{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sunset-editor",
   "metadata": {},
   "source": [
    "# EGM722 - Week 4 Practical: Raster data using rasterio\n",
    "\n",
    "## Overview\n",
    "Up to now, you have gained some experience working with basic features of python, used cartopy and matplotlib to create a map, and explored using shapely and geopandas to work with vector data. In this week's practical, we'll be looking at working with raster data using rasterio and numpy.\n",
    "\n",
    "## Objectives\n",
    "-  Learn about opening and viewing raster data using rasterio and cartopy\n",
    "-  Become familiar with opening files using a `with` statement\n",
    "-  Use `*` and `**` to unpack arguments in a function\n",
    "-  Use rasterio to reproject raster data\n",
    "\n",
    "## Data provided\n",
    "\n",
    "In the data\\_files folder, you should have the following files:\n",
    "-  NI\\_mosaic.tif\n",
    "\n",
    "## 1. Getting started\n",
    "In this practical, we'll be working with raster data. As a quick refresher, raster data are gridded datasets that contain anything from aerial and satellite images to elevation, temperature, or classisfied land cover. A raster is made up of pixels (or cells), where each pixel value represents the dataset's value at a given location.\n",
    "\n",
    "To get started, run the following cell to import rasterio and matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-talent",
   "metadata": {},
   "source": [
    "In the box below, we load the dataset using `rio.open()`, then view some of the attributes of the dataset. \n",
    "\n",
    "`rio.open()` creates a [__DatasetReader__](https://rasterio.readthedocs.io/en/latest/api/rasterio.io.html#rasterio.io.DatasetReader) object that we use to read the dataset and its attributes. When we do this, we don't actually load the full raster into memory - we just open the file and read the metadata and other attributes. Later on, we'll load the raster into memory; for now, we'll look at the different attributes of the __DatasetReader__ object.\n",
    "\n",
    "For starters, the `name` attribute is the filename for the dataset, and the `mode` refers to how the dataset has been opened (`r` for read, `w` for write, `r+` for read/write). We can also check how many _layers_, or _bands_, the datset has using `count`, and check the size of the image using `width` and `height`. Finally, we can see the different types of data (e.g., integer, floating point, etc.) that each band has using `dtypes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rio.open('data_files/NI_Mosaic.tif')\n",
    "\n",
    "print('{} opened in {} mode'.format(dataset.name,dataset.mode))\n",
    "print('image has {} band(s)'.format(dataset.count))\n",
    "print('image size (width, height): {} x {}'.format(dataset.width, dataset.height))\n",
    "print('band 1 dataype is {}'.format(dataset.dtypes[0])) # note that the band name (Band 1) differs from the list index [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-wheat",
   "metadata": {},
   "source": [
    "We can also look at the georeferencing information for the dataset. The `bounds` attribute gives locations for the left, bottom, right, and top sides of the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-logic",
   "metadata": {},
   "source": [
    "Note that these values are in the coordinate reference system (CRS) of the dataset, which we can view using the `crs` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-milton",
   "metadata": {},
   "source": [
    "This dataset has a CRS of __EPSG:32629__, which corresponds to WGS84 UTM Zone 29N. Finally, the `transform` of a dataset is a 2x3 affine transformation matrix that maps pixel locations to real-world coordinates. The matrix has the following form:\n",
    "\n",
    "```\n",
    "| a b c |\n",
    "| d e f |\n",
    "```\n",
    "\n",
    "where _a_ corresponds to the pixel width, _b_ is the row rotation (normally 0), _c_ is the x coordinate of the upper-left corner of the image, _d_ is the column rotation (normally 0), _e_ is the height of a pixel, and _f_ is the y coordinate of the upper-left corner of the image.\n",
    "\n",
    "\n",
    "## 2. Loading the data\n",
    "To load the data, we use the `read()` [method](https://rasterio.readthedocs.io/en/latest/api/rasterio.io.html#rasterio.io.DatasetReader.read) of the __DatasetReader__ object. This returns a [numpy](https://numpy.org/doc/stable/) array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dataset.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-correspondence",
   "metadata": {},
   "source": [
    "By default, `read()` will load all of the bands associated with the dataset. To load specific bands, we can pass individual indices, or a list of indices, that we want to load (e.g., `dataset.read(1)` to load the first band or `dataset.read([1, 2])` to load the first 2 bands). \n",
    "\n",
    "Note that when we pass indices to the `read()` method, we start indexing from 1, rather than 0. This is not the case for the array that is returned, however - here, the indices start from 0. This can be confusing, so it's good to pay attention to what kind of object you are working with when you start indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.shape) # returns a tuple with the number of image bands bands, image height, and image width.\n",
    "print(img[7]) # will return an IndexError, because while there are 7 bands, the indices range from 0 to 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-vocabulary",
   "metadata": {},
   "source": [
    "If we want to get a specific pixel value, we can index the array just like we would a __list__ or __tuple__. For example, to get the value of the center pixel in Band 1, we can do the following. For the arrays that we are using, the first index corresponds to the band (if there's more than one band), the second index (first index if there's only one band) corresponds to the row (y) location, and the third (second) index corresponds to the column (x) location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img[0, dataset.height // 2, dataset.width // 2]) # note that // performs floor division, as indices have to be integers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-candy",
   "metadata": {},
   "source": [
    "Using the __DatasetReader__ object, we can also find the pixel indices corresponding to spatial locations, and vice-versa, using both the `index()` method and the `transform` attribute. Note that the spatial locations should be in the same CRS as the image transform - if they are not, the image indices returned might not make sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "centeri, centerj = dataset.height // 2, dataset.width // 2 # note that centeri corresponds to the row, and centerj the column\n",
    "centerx, centery = dataset.transform * (centerj, centeri) # note the reversal here, from i,j to j,i\n",
    "print(dataset.index(centerx, centery))\n",
    "print((centeri, centerj) == dataset.index(centerx, centery)) # check that these are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-emphasis",
   "metadata": {},
   "source": [
    "If we don't want to load the whole image at once, we can also choose a `window` using `read`. The format for this is a __tuple__ of __tuples__ corresponding to the top/bottom indices and left/right indices of the window. We can combine this with `index()` to load a subset of the image based on spatial location (for example, using a vector dataset). Here, we can select a 1 km window around the center pixel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "top, lft = dataset.index(centerx-500, centery+500)\n",
    "bot, rgt = dataset.index(centerx+500, centery-500)\n",
    "\n",
    "subset = dataset.read(window=((top, bot), (lft, rgt))) # format is (top, bottom), (left, right)\n",
    "\n",
    "dataset.close() # remember to close the dataset now that we're done with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-connection",
   "metadata": {},
   "source": [
    "## 3. The with statement\n",
    "In python, we use the built-in `open()` function to open files on the disk, in almost exactly the same way that `rasterio.open()` works. If you were to run the line of code below, you would see an output like this:\n",
    "\n",
    "```python\n",
    "In [42]: dataset\n",
    "Out[42]: <open DatasetReader name='data_files/NI_Mosaic.tif' mode='r'>\n",
    "```\n",
    "\n",
    "Here, the file is `open`, with a mode `r` for reading. Once we are done with the file (either reading, writing, appending, or whatever it happens to be), we have to remember to _close_ the file using the `close()` method:\n",
    "\n",
    "```python\n",
    "f = open('my_file.txt', 'w')\n",
    "...\n",
    "f.close()\n",
    "```\n",
    "\n",
    "However, sometimes things happen. For example, an exception might be raised, or the interpreter might crash, and the file might [stay open](https://askubuntu.com/a/701536).\n",
    "\n",
    "One way that we can handle opening/closing files without having to remember to explicitly close them is using a `with` statement:\n",
    "\n",
    "```python\n",
    "with open('my_file.txt', 'w') as f:\n",
    "    ...\n",
    "```\n",
    "\n",
    "This is exactly the same as what's written above - within the `with` statement, we can use the variable `f` exactly as we would in the other example. In the cell below, we can re-open the dataset, extract the different attributes that we will need for the next few exercises, and then close the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open('data_files/NI_Mosaic.tif') as dataset:\n",
    "    img = dataset.read()\n",
    "    xmin, ymin, xmax, ymax = dataset.bounds    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-unemployment",
   "metadata": {},
   "source": [
    "## 4. Displaying raster data using matplotlib and cartopy\n",
    "\n",
    "Now that we've loaded our image, we can use cartopy and matplotlib to display it, just like we did for mapping vector data in Weeks 2 and 3. To start, we'll create a new cartopy __CRS__ object, and use this to create a matplotlib __Axes__ object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-promotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "myCRS = ccrs.UTM(29) # note that this matches with the CRS of our image\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10), subplot_kw=dict(projection=myCRS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-bracket",
   "metadata": {},
   "source": [
    "Now, we will use [`imshow()`](https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.imshow.html) to display a single band from our image. We'll use the [Landsat](https://www.usgs.gov/faqs/what-are-band-designations-landsat-satellites?qt-news_science_products=0#qt-news_science_products) Near Infrared band - for our image, which is based on Landsat 5 TM images, this is Band 4 (remember that this corresponds to index 3 of our bands array):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.imshow(img[3], cmap='gray', vmin=200, vmax=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-configuration",
   "metadata": {},
   "source": [
    "As you can see from the link above, `imshow()` has a number of arguments that we can use to display our image. As we are using only a single band, we can set the minimum (`vmin`) and maximum (`vmax`) values of the image to stretch the display to, as well as what colormap to use (`cmap`). For more information about colormaps, you can check out [this tutorial](https://matplotlib.org/stable/tutorials/colors/colormaps.html), as well as a recent [paper](https://www.nature.com/articles/s41467-020-19160-7) on the (mis)use of color in science.\n",
    "\n",
    "But, mouse over the figure window above - what coordinates do you see in the bottom right corner? Do they look correct? By default, `imshow()` uses the row/column indices of the image, rather than the geographic coordinates. To set these properly, we have to tell `imshow()` both the `tranform` (CRS) to use, as well as the `extent` of the image. Run the cell below, then mouse back over the figure above. The coordinates (both the projected and geographic coordinates) should look more correct now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.imshow(img[3], cmap='gray', vmin=200, vmax=5000, transform=myCRS, extent=[xmin, xmax, ymin, ymax])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-jersey",
   "metadata": {},
   "source": [
    "This is not the only way that we can display images, however. We can also display them as RGB color composites. Try the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.imshow(img[0:3], transform=myCRS, extent=[xmin, xmax, ymin, ymax])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-gravity",
   "metadata": {},
   "source": [
    "So that didn't work. Remember that `dataset.read()` loaded the raster in a way that the bands are the first index, the rows are the second index, and the columns are the third index. But, `imshow()` expects that the image indices are in the order (rows, columns, bands). From the documentation, we also see that:\n",
    "\n",
    "```\n",
    "\t\n",
    "X: array-like or PIL image\n",
    "    The image data. Supported array shapes are:\n",
    "\n",
    "    (M, N): an image with scalar data. The values are mapped to colors using normalization and a colormap. \n",
    "        See parameters norm, cmap, vmin, vmax.\n",
    "    (M, N, 3): an image with RGB values (0-1 float or 0-255 int).\n",
    "    (M, N, 4): an image with RGBA values (0-1 float or 0-255 int), i.e. including transparency.\n",
    "    The first two dimensions (M, N) define the rows and columns of the image.\n",
    "\n",
    "    Out-of-range RGB(A) values are clipped.\n",
    "```\n",
    "\n",
    "So, we need to also scale our image to have values between 0-1 (or 0-255). We could try do this each and every time that we want to display an image, but this makes for unreadable code and also increases the likelihood that we will make a mistake writing our code. In other words, this is a perfect place to write a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_display(image, ax, bands, transform, extent):\n",
    "    '''\n",
    "    This is where you should write a docstring.\n",
    "    '''\n",
    "    # first, we transpose the image to re-order the indices\n",
    "    dispimg = image.transpose([1, 2, 0])\n",
    "    \n",
    "    # next, we have to scale the image.\n",
    "    dispimg = dispimg / dispimg.max()\n",
    "    \n",
    "    # finally, we display the image\n",
    "    handle = ax.imshow(dispimg[:, :, bands], transform=transform, extent=extent)\n",
    "    \n",
    "    return handle, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-nightlife",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "h, ax = img_display(img, ax, [2, 1, 0], myCRS, [xmin, xmax, ymin, ymax])\n",
    "fig # just to save you from scrolling back up to see"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-scholarship",
   "metadata": {},
   "source": [
    "So that worked, but the image is very dark - this is because of the way the we \"normalized\" the values to fall between 0 and 1, using the maximum of all of the bands: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-muscle",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxvals = [img[i].max() for i in range(dataset.count)]\n",
    "print(maxvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-arthritis",
   "metadata": {},
   "source": [
    "From the code below, we see that not all of the bands have the same range of values. Bands 1-3 have fairly low maximum values (2500-4100), while Band 5 has the highest values of all, over twice as high as in bands 1-3. So, rather than normalizing using the maximum value of all of the bands, we might want to instead normalize based on the maximum value of a given band. However, that might still result in dark or washed-out images. Let's instead try a [percentile stretch](https://theailearner.com/2019/01/30/contrast-stretching/), which should give a bit nicer results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile_stretch(image, pmin=0., pmax=100.):\n",
    "    '''\n",
    "    This is where you should write a docstring.\n",
    "    '''\n",
    "    # here, we make sure that pmin < pmax, and that they are between 0, 100\n",
    "    if not 0 <= pmin < pmax <= 100:\n",
    "        raise ValueError('0 <= pmin < pmax <= 100')\n",
    "    # here, we make sure that the image is only 2-dimensional\n",
    "    if not image.ndim == 2:\n",
    "        raise ValueError('Image can only have two dimensions (row, column)')\n",
    "    \n",
    "    minval = np.percentile(image, pmin)\n",
    "    maxval = np.percentile(image, pmax)\n",
    "    \n",
    "    stretched = (image - minval) / (maxval - minval) # stretch the image to 0, 1\n",
    "    stretched[image < minval] = 0 # set anything less than minval to the new minimum, 0.\n",
    "    stretched[image > maxval] = 1 # set anything greater than maxval to the new maximum, 1.\n",
    "    \n",
    "    return stretched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-fortune",
   "metadata": {},
   "source": [
    "Here, we have a few things happening. In the function header, we have two parameters, _pmin_ and _pmax_, that we provide default values of 0 and 100, respectively:\n",
    "\n",
    "```python\n",
    "def percentile_stretch(image, pmin=0, pmax=100):\n",
    "    ...\n",
    "```\n",
    "    \n",
    "We've seen this before, but it's worth re-stating here that if we call the function like this:\n",
    "\n",
    "```python\n",
    "    stretched = percentile_stretch(img)\n",
    "```\n",
    "\n",
    "It will use the default values for _pmin_ and _pmax_. Using default values like this provides us a way to make sure that necessary parameters are always set, without us always having to remember to set them when we call a function.\n",
    "\n",
    "Next, note the two conditional statements at the beginning of the function. We first check that pmin >= 0 (because it's a percentage), that pmin < pmax, and that pmax <= 100 (because it's a percentage). If any of these things are not true, we __raise__ a __ValueError__, with a message indicating what caused the error. We also want to make sure that our image only has two dimensions (i.e., we are operating on a single band), so we check that the number of dimensions (`ndim`) is equal to 2.\n",
    "\n",
    "After that, we stretch the image to values between 0 and 1, and make sure to set any values below our minimum/maximum values to be equal to 0 or 1, respectively.\n",
    "\n",
    "Now, we should update `img_display()` to use `percentile_stretch()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_display(image, ax, bands, transform, extent, pmin=0, pmax=100):\n",
    "    '''\n",
    "    This is where you should write a docstring.\n",
    "    '''\n",
    "    dispimg = image.copy().astype(np.float32) # make a copy of the original image,\n",
    "    # but be sure to cast it as a floating-point image, rather than an integer\n",
    "\n",
    "    for b in range(image.shape[0]): # loop over each band, stretching using percentile_stretch()\n",
    "        dispimg[b] = percentile_stretch(image[b], pmin=pmin, pmax=pmax)\n",
    "\n",
    "    # next, we transpose the image to re-order the indices\n",
    "    dispimg = dispimg.transpose([1, 2, 0])\n",
    "    \n",
    "    # finally, we display the image\n",
    "    handle = ax.imshow(dispimg[:, :, bands], transform=transform, extent=extent)\n",
    "    \n",
    "    return handle, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-ranch",
   "metadata": {},
   "source": [
    "Now, run the new function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, ax = img_display(img, ax, [2, 1, 0], myCRS, [xmin, xmax, ymin, ymax], pmin=0.1, pmax=99.9)\n",
    "fig # just to save you from scrolling back up to see"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-station",
   "metadata": {},
   "source": [
    "That looks much better - we can now see the image, it has good contrast, and the image is displayed in the correct location on the map (you can verify this by mousing over the figure).\n",
    "\n",
    "## 5. functions with \\*args and \\*\\*kwargs\n",
    "\n",
    "At the moment, however, our function has a lot of extra parameters/arguments:\n",
    "\n",
    "```python\n",
    "def img_display(image, ax, bands, transform, extent, pmin=0, pmax=100):\n",
    "    ...\n",
    "```\n",
    "\n",
    "Rather than explicitly specifying the transform and extent each time, for example, we can change this to use the [unpacking operator](https://realpython.com/python-kwargs-and-args/), `**`. In this way, we can define a __dict__ of keyword arguments (kwargs) to pass to `percentile_stretch()` and `ax.imshow()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-thong",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def new_img_display(image, ax, bands, stretch_args=None, **imshow_args):\n",
    "    '''\n",
    "    This is where you should write a docstring.\n",
    "    '''\n",
    "    dispimg = image.copy().astype(np.float32) # make a copy of the original image,\n",
    "    # but be sure to cast it as a floating-point image, rather than an integer\n",
    "\n",
    "    for b in range(image.shape[0]): # loop over each band, stretching using percentile_stretch()\n",
    "        if stretch_args is None: # if stretch_args is None, use the default values for percentile_stretch\n",
    "            dispimg[b] = percentile_stretch(image[b])\n",
    "        else:\n",
    "            dispimg[b] = percentile_stretch(image[b], **stretch_args)\n",
    "\n",
    "    # next, we transpose the image to re-order the indices\n",
    "    dispimg = dispimg.transpose([1, 2, 0])\n",
    "    \n",
    "    # finally, we display the image\n",
    "    handle = ax.imshow(dispimg[:, :, bands], **imshow_args)\n",
    "    \n",
    "    return handle, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-simulation",
   "metadata": {},
   "source": [
    "Now, create a __dict__ called my_kwargs with keys `extent` and `transform`, using the values we passed to `ax.imshow()` previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_kwargs = {'extent': [xmin, xmax, ymin, ymax],\n",
    "             'transform': myCRS}\n",
    "\n",
    "my_stretch = {'pmin': 0.1, 'pmax': 99.9}\n",
    "\n",
    "h, ax = new_img_display(img, ax, [2, 1, 0], stretch_args=my_stretch, **my_kwargs)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-preference",
   "metadata": {},
   "source": [
    "You should see that this is the same image as before - the only thing that's changed is how we call the function. Feel free to try different stretch values, to see how it changes the image. If you're interested in learning more about Landsat [band combinations](https://youtu.be/jc8NVHwjhlQ) and [image enhancement](https://youtu.be/LYVi7F4U8Eg) in general, you are welcome to watch the lecture videos provided by these links.\n",
    "\n",
    "## 6. Reprojecting rasters using rasterio\n",
    "Fortunately, our image was provided in a geographic format that matches what we've been working with (WGS84 UTM Zone 29N). But, what if we need to have our image in a different format? In that case, we can use the `rasterio.warp` sub-module to reproject the image. The example below comes directly from an example provided in the [rasterio documentation](https://rasterio.readthedocs.io/en/latest/topics/reproject.html#reprojecting-a-geotiff-dataset), and it makes use of two concepts that we've introduced in this practical: the `with` statement, and `**kwargs`. For more details about the different functions, such as `rasterio.warp.calculate_default_transform()` or `rasterio.warp.reproject`, check out the [documentation](https://rasterio.readthedocs.io/en/latest/api/rasterio.warp.html).\n",
    "\n",
    "The first part of this example:\n",
    "```python\n",
    "with rio.open('data_files/NI_Mosaic.tif') as src:\n",
    "    transform, width, height = rio.warp.calculate_default_transform(\n",
    "            src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "```\n",
    "\n",
    "opens the `NI_Mosaic.tif` file, and find the new `transform`, `width`, and `height` attribute values for the reprojected (output) raster. Next, we copy the `meta` attribute, a `dict` object, from the source dataset:\n",
    "\n",
    "```python\n",
    "    kwargs = src.meta.copy()\n",
    "```\n",
    "\n",
    "We then `update` (change) some of the attributes of the `dict` object to match the output dataset:\n",
    "\n",
    "```python\n",
    "    kwargs.update({\n",
    "        'crs': dst_crs,\n",
    "        'transform': transform,\n",
    "        'width': width,\n",
    "        'height': height\n",
    "    })\n",
    "```\n",
    "\n",
    "Finally, we open the new (reprojected) dataset, and reproject each band from the source dataset to the output dataset, using a nearest-neighbor resampling (`Resampling.nearest`):\n",
    "\n",
    "```python\n",
    "    with rio.open('data_files/NI_Mosaic_ITM.tif', 'w', **kwargs) as dst:\n",
    "        for i in range(1, src.count + 1): # ranging from 1 to the number of bands + 1\n",
    "            rio.warp.reproject(\n",
    "                source=rio.band(src, i),\n",
    "                destination=rio.band(dst, i),\n",
    "                src_transform=src.transform,\n",
    "                src_crs=src.crs,\n",
    "                dst_transform=transform,\n",
    "                dst_crs=dst_crs,\n",
    "                resampling=Resampling.nearest)\n",
    "```\n",
    "\n",
    "Note that this example only reprojects the raster from one CRS to another. If we wanted to, say, reproject the raster while also changing the pixel size or cropping to a particular data frame, we would need to calculate the new `transform`, `width`, and `height` values accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-wisdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio.warp # note: we will be able to use rio.warp here, since we've previously imported rasterio as rio.\n",
    "dst_crs = 'epsg:2157' # irish transverse mercator EPSG code\n",
    "\n",
    "with rio.open('data_files/NI_Mosaic.tif') as src:\n",
    "    transform, width, height = rio.warp.calculate_default_transform(\n",
    "            src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "    kwargs = src.meta.copy() # this copies the meta dict object\n",
    "    kwargs.update({\n",
    "        'crs': dst_crs,\n",
    "        'transform': transform,\n",
    "        'width': width,\n",
    "        'height': height\n",
    "    }) # note: to change the values in a dictionary, we use the update() method\n",
    "    \n",
    "    with rio.open('data_files/NI_Mosaic_ITM.tif', 'w', **kwargs) as dst:\n",
    "        for i in range(1, src.count + 1): # ranging from 1 to the number of bands + 1\n",
    "            rio.warp.reproject(\n",
    "                source=rio.band(src, i),\n",
    "                destination=rio.band(dst, i),\n",
    "                src_transform=src.transform,\n",
    "                src_crs=src.crs,\n",
    "                dst_transform=transform,\n",
    "                dst_crs=dst_crs,\n",
    "                resampling=rio.warp.Resampling.nearest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-silence",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "That wraps up the practical for this week. Next week, we'll look at some more programming concepts, as well as ways that we can work with both raster data and vector data. In the meantime, use the `assignment_script.py` file in the Week4 folder to work on a script that combines the concepts we've used this week, as well as some of the material from previous weeks, to produce a map that overlays the county borders and town/city locations on the satellite image provided. \n",
    "\n",
    "For an additional challenge, try this: In the image below, notice how the area outside of the county borders has been covered by a semi-transparent overlay. Can you work out how to do this? Check over the `import` statements in `assignment_script.py` __carefully__ - there's at least one import that we haven't used yet, but it should help point you in the right direction. \n",
    "\n",
    "I'll provide my example next week, but try to think about the different steps involved and how you might solve this, using some of the examples provided in previous weeks. Good luck!\n",
    "\n",
    "![Example map for Week 4 assignment](imgs/example_map.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
